{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bibliographic-kingdom",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "partial-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-impact",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "original-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'v1', 'v2', 'BlockAddition', 'BlockEdit', 'BlockRelocation',\n",
       "       'BlockRemoval', 'RoleVariableAddition', 'RoleVariableEdit',\n",
       "       'RoleVariableRelocation', 'RoleVariableRemoval', 'RoleVarFileAddition',\n",
       "       'RoleVarFileRelocation', 'RoleVarFileRemoval',\n",
       "       'DefaultVariableAddition', 'DefaultVariableEdit',\n",
       "       'DefaultVariableRelocation', 'DefaultVariableRemoval',\n",
       "       'DefaultVarFileAddition', 'DefaultVarFileRelocation',\n",
       "       'DefaultVarFileRemoval', 'DependencyAddition', 'DependencyRemoval',\n",
       "       'HandlerBlockAddition', 'HandlerBlockEdit', 'HandlerBlockRelocation',\n",
       "       'HandlerBlockRemoval', 'HandlerTaskAddition', 'HandlerTaskEdit',\n",
       "       'HandlerTaskRelocation', 'HandlerTaskRemoval', 'HandlerFileAddition',\n",
       "       'HandlerFileRelocation', 'HandlerFileRemoval', 'MetaEdit',\n",
       "       'PlatformAddition', 'PlatformRemoval', 'TaskAddition', 'TaskEdit',\n",
       "       'TaskRelocation', 'TaskRemoval', 'TaskFileAddition',\n",
       "       'TaskFileRelocation', 'TaskFileRemoval', 'release'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"data/new_data/old_records.csv.gz\")\n",
    "\n",
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-weekend",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convinced-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity of the data:\n",
      "0 out of 71722 contains at least one null value representing 0.0 % of the instances\n"
     ]
    }
   ],
   "source": [
    "data_null_values = dataframe[dataframe.isna().any(axis=1)]\n",
    "len_null = len(data_null_values)\n",
    "len_data = len(dataframe)\n",
    "\n",
    "# Print message\n",
    "print(\"Validity of the data:\")\n",
    "print(f\"{len_null} out of {len_data} contains at least one null value\", end=\" \")\n",
    "print(f\"representing {len_null / len_data} % of the instances\")\n",
    "\n",
    "# Discarding the first three columns and the column with all values as zero\n",
    "filtered_data = dataframe.drop(['id', 'v1', 'v2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-active",
   "metadata": {},
   "source": [
    "### Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "subsequent-september",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TaskEdit              TaskRelocation          0.733124\n",
      "TaskRelocation        TaskEdit                0.733124\n",
      "HandlerTaskAddition   HandlerBlockAddition    0.752078\n",
      "HandlerBlockAddition  HandlerTaskAddition     0.752078\n",
      "BlockAddition         TaskAddition            0.762167\n",
      "TaskAddition          BlockAddition           0.762167\n",
      "TaskFileAddition      BlockAddition           0.764727\n",
      "BlockAddition         TaskFileAddition        0.764727\n",
      "BlockRemoval          TaskFileRemoval         0.790119\n",
      "TaskFileRemoval       BlockRemoval            0.790119\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = filtered_data.corr()\n",
    "unstacked_correlation_matrix = correlation_matrix.unstack()\n",
    "sorted_values = unstacked_correlation_matrix.sort_values(kind=\"quicksort\")\n",
    "print()\n",
    "print(sorted_values[1630:1640])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-contrary",
   "metadata": {},
   "source": [
    "### Transform data into Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fifty-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes of the data:\n",
      "(71722, 41)\n",
      "(71722,)\n"
     ]
    }
   ],
   "source": [
    "to_transform = {\"release\": {\"patch\": 0, \"minor\": 1, \"major\": 2}}\n",
    "filtered_data.replace(to_transform, inplace=True)\n",
    "\n",
    "# Transforming data into Numpy arrays\n",
    "X = filtered_data[filtered_data.columns[:-1]].to_numpy()\n",
    "y = filtered_data[filtered_data.columns[-1]].to_numpy()\n",
    "\n",
    "# Print shapes\n",
    "print()\n",
    "print(\"Shapes of the data:\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-westminster",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-pantyhose",
   "metadata": {},
   "source": [
    "#### Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nearby-thesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53237, 15215, 3270)\n",
      "\n",
      "Shapes of the data:\n",
      "(58451, 41)\n",
      "(58451,)\n",
      "\n",
      "(48639, 6542, 3270)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss, NeighbourhoodCleaningRule\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "undersample = NeighbourhoodCleaningRule(n_jobs=-1)\n",
    "\n",
    "print((len(X[y==0]), len(X[y==1]), len(X[y==2])))\n",
    "\n",
    "X, y = undersample.fit_resample(X, y)\n",
    "\n",
    "# Print shapes\n",
    "print()\n",
    "print(\"Shapes of the data:\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print()\n",
    "print((len(X[y==0]), len(X[y==1]), len(X[y==2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-valuation",
   "metadata": {},
   "source": [
    "### Configuring classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minute-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-organic",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "touched-valuable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal number of features : 37\n",
      "\n",
      "Original Features on Data:  ['BlockAddition', 'BlockEdit', 'BlockRelocation', 'BlockRemoval', 'RoleVariableAddition', 'RoleVariableEdit', 'RoleVariableRelocation', 'RoleVariableRemoval', 'RoleVarFileAddition', 'RoleVarFileRelocation', 'RoleVarFileRemoval', 'DefaultVariableAddition', 'DefaultVariableEdit', 'DefaultVariableRelocation', 'DefaultVariableRemoval', 'DefaultVarFileAddition', 'DefaultVarFileRelocation', 'DefaultVarFileRemoval', 'DependencyAddition', 'DependencyRemoval', 'HandlerBlockAddition', 'HandlerBlockEdit', 'HandlerBlockRelocation', 'HandlerBlockRemoval', 'HandlerTaskAddition', 'HandlerTaskEdit', 'HandlerTaskRelocation', 'HandlerTaskRemoval', 'HandlerFileAddition', 'HandlerFileRelocation', 'HandlerFileRemoval', 'MetaEdit', 'PlatformAddition', 'PlatformRemoval', 'TaskAddition', 'TaskEdit', 'TaskRelocation', 'TaskRemoval', 'TaskFileAddition', 'TaskFileRelocation', 'TaskFileRemoval']\n",
      "Ranking of Features:  [1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 3 5 1 1 1 1 1 1 4 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "Selected Features:  ['BlockAddition', 'BlockEdit', 'BlockRelocation', 'BlockRemoval', 'RoleVariableAddition', 'RoleVariableEdit', 'RoleVariableRelocation', 'RoleVariableRemoval', 'RoleVarFileAddition', 'RoleVarFileRelocation', 'RoleVarFileRemoval', 'DefaultVariableAddition', 'DefaultVariableEdit', 'DefaultVariableRemoval', 'DefaultVarFileAddition', 'DefaultVarFileRelocation', 'DefaultVarFileRemoval', 'DependencyAddition', 'DependencyRemoval', 'HandlerBlockAddition', 'HandlerBlockRemoval', 'HandlerTaskAddition', 'HandlerTaskEdit', 'HandlerTaskRelocation', 'HandlerTaskRemoval', 'HandlerFileAddition', 'HandlerFileRemoval', 'MetaEdit', 'PlatformAddition', 'PlatformRemoval', 'TaskAddition', 'TaskEdit', 'TaskRelocation', 'TaskRemoval', 'TaskFileAddition', 'TaskFileRelocation', 'TaskFileRemoval']\n",
      "Discarded Features:  ['DefaultVariableRelocation', 'HandlerBlockRelocation', 'HandlerFileRelocation', 'HandlerBlockEdit']\n"
     ]
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=clf, step=1, cv=StratifiedKFold(10), scoring='f1_macro')\n",
    "X_new = rfecv.fit_transform(X, y)\n",
    "\n",
    "print()\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "column_names = filtered_data.columns[:-1].tolist()\n",
    "selected_features = list()\n",
    "\n",
    "for i, value in enumerate(rfecv.support_):\n",
    "    if value:\n",
    "        selected_features.append(column_names[i])\n",
    "\n",
    "print()\n",
    "print(\"Original Features on Data: \", column_names)\n",
    "print(\"Ranking of Features: \", rfecv.ranking_)\n",
    "print(\"Selected Features: \", selected_features)\n",
    "\n",
    "discarded_features = list(set(column_names).difference(set(selected_features)))\n",
    "print(\"Discarded Features: \", discarded_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-roads",
   "metadata": {},
   "source": [
    "### Stratified Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promotional-inventory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of Precisions:  0.8371557497695594\n",
      "Mean of Recalls:  0.7565171016649413\n",
      "Confusion matrix:\n",
      "[[47625   667   347]\n",
      " [  585  5769   188]\n",
      " [ 1445   489  1336]]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "X = X_new\n",
    "\n",
    "precision_scores = list()\n",
    "recall_scores = list()\n",
    "confusion_matrices = list()\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    clf.fit(X[train], y[train])\n",
    "    y_predict = clf.predict(X[test])\n",
    "\n",
    "    precision_value = precision_score(y[test], y_predict, average=\"macro\")\n",
    "    recall_value = recall_score(y[test], y_predict, average=\"macro\")\n",
    "    conf_matrix = confusion_matrix(y[test], y_predict)\n",
    "\n",
    "    precision_scores.append(precision_value)\n",
    "    recall_scores.append(recall_value)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "\n",
    "print()\n",
    "print(\"Mean of Precisions: \", np.mean(precision_scores))\n",
    "print(\"Mean of Recalls: \", np.mean(recall_scores))\n",
    "    \n",
    "print(\"Confusion matrix:\")\n",
    "print(sum(confusion_matrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-likelihood",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qualified-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "pickle.dump(clf, open(\"data/models/randomForest_old_data.pickle\", \"wb\"))\n",
    "\n",
    "# Data Transformed\n",
    "pickle.dump(X, open(\"data/transformed_data/X_train_old.pickle\", \"wb\"))\n",
    "pickle.dump(y, open(\"data/transformed_data/y_train_old.pickle\", \"wb\"))\n",
    "\n",
    "# Feature-related\n",
    "pickle.dump(column_names, open(\"data/features/features.pickle\", \"wb\"))\n",
    "pickle.dump(rfecv.ranking_, open(\"data/features/ranking_features.pickle\", \"wb\"))\n",
    "pickle.dump(selected_features, open(\"data/features/selected_features.pickle\", \"wb\"))\n",
    "pickle.dump(discarded_features, open(\"data/features/discarded_features.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
