{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "engaging-dream",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "junior-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import RFECV, RFE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-relevance",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "applicable-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data/new_data/old_records.csv.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-tackle",
   "metadata": {},
   "source": [
    "### Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saved-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity of the data:\n",
      "0 out of 66137 contains at least one null value representing 0.0 % of the instances\n"
     ]
    }
   ],
   "source": [
    "data_null_values = dataframe[dataframe.isna().any(axis=1)]\n",
    "len_null = len(data_null_values)\n",
    "len_data = len(dataframe)\n",
    "\n",
    "# Print message\n",
    "print(\"Validity of the data:\")\n",
    "print(f\"{len_null} out of {len_data} contains at least one null value\", end=\" \")\n",
    "print(f\"representing {len_null / len_data} % of the instances\")\n",
    "\n",
    "cleaned_data = dataframe.dropna(how='any', axis=0)\n",
    "float_columns = cleaned_data.select_dtypes(include=['float64'])\n",
    "\n",
    "for col in float_columns.columns.values:\n",
    "    cleaned_data[col] = cleaned_data[col].astype('int64')\n",
    "\n",
    "filtered_data = cleaned_data.drop(['id', 'v1', 'v2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-intellectual",
   "metadata": {},
   "source": [
    "### Correlation analysis (Changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atlantic-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most correlated features:\n",
      "TaskAddition           BlockAddition            0.708950\n",
      "BlockAddition          TaskAddition             0.708950\n",
      "                       TaskFileAddition         0.721393\n",
      "TaskFileAddition       BlockAddition            0.721393\n",
      "TaskRelocation         TaskAddition             0.748993\n",
      "TaskAddition           TaskRelocation           0.748993\n",
      "HandlerTaskRelocation  HandlerBlockRemoval      0.764927\n",
      "HandlerBlockRemoval    HandlerTaskRelocation    0.764927\n",
      "HandlerBlockAddition   HandlerTaskAddition      0.824182\n",
      "HandlerTaskAddition    HandlerBlockAddition     0.824182\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = filtered_data.corr(method=\"spearman\")\n",
    "unstacked_correlation_matrix = correlation_matrix.unstack()\n",
    "sorted_values = unstacked_correlation_matrix.sort_values(kind=\"quicksort\")\n",
    "\n",
    "# Most correlated features excluding comparison between the same features\n",
    "print()\n",
    "print(\"Most correlated features:\")\n",
    "print(sorted_values[1630:1640])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-treasurer",
   "metadata": {},
   "source": [
    "### Droping the second correlated feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "transparent-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping second correlated feature\n",
    "filtered_data = filtered_data.drop(['HandlerBlockAddition'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-crisis",
   "metadata": {},
   "source": [
    "### Transforming data into Numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weird-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shapes of the data:\n",
      "(66137, 40)\n",
      "(66137,)\n"
     ]
    }
   ],
   "source": [
    "to_transform = {\"release\": {\"patch\": 0, \"minor\": 1, \"major\": 2}}\n",
    "filtered_data.replace(to_transform, inplace=True)\n",
    "\n",
    "X = filtered_data[filtered_data.columns[:-1]].to_numpy()\n",
    "y = filtered_data[filtered_data.columns[-1]].to_numpy()\n",
    "\n",
    "# Print shapes\n",
    "print()\n",
    "print(\"Shapes of the data:\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-formula",
   "metadata": {},
   "source": [
    "### Normalisation for the model that's going to select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "psychological-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "transformer = RobustScaler()\n",
    "X_normal = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-government",
   "metadata": {},
   "source": [
    "### Configuring classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "super-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-grass",
   "metadata": {},
   "source": [
    "### All feature importance weights by the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controversial-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the features:\n",
      "BlockAddition --> 0.039648374943447647\n",
      "BlockEdit --> 0.006993247683843925\n",
      "BlockRelocation --> 0.007363420330569246\n",
      "BlockRemoval --> 0.023507362073561182\n",
      "RoleVariableAddition --> 0.0447254176815704\n",
      "RoleVariableEdit --> 0.0340306215259378\n",
      "RoleVariableRelocation --> 0.0017671864240601885\n",
      "RoleVariableRemoval --> 0.020916053550904756\n",
      "RoleVarFileAddition --> 0.01635927918633266\n",
      "RoleVarFileRelocation --> 0.003931998623383815\n",
      "RoleVarFileRemoval --> 0.008080246554922333\n",
      "DefaultVariableAddition --> 0.11958434658399393\n",
      "DefaultVariableEdit --> 0.048997465538168694\n",
      "DefaultVariableRelocation --> 0.0002564869009449184\n",
      "DefaultVariableRemoval --> 0.04283327016715107\n",
      "DefaultVarFileAddition --> 0.005643632810421509\n",
      "DefaultVarFileRelocation --> 0.0003889098762036113\n",
      "DefaultVarFileRemoval --> 0.0018192655469374617\n",
      "DependencyAddition --> 0.008862047612200212\n",
      "DependencyRemoval --> 0.007278095081349463\n",
      "HandlerBlockEdit --> 1.0455925667852486e-05\n",
      "HandlerBlockRelocation --> 1.2777487477660295e-05\n",
      "HandlerBlockRemoval --> 0.004159259398139019\n",
      "HandlerTaskAddition --> 0.008773587800951593\n",
      "HandlerTaskEdit --> 0.01981919284286484\n",
      "HandlerTaskRelocation --> 0.005230301024165859\n",
      "HandlerTaskRemoval --> 0.0028787682892862146\n",
      "HandlerFileAddition --> 0.0037523451196292646\n",
      "HandlerFileRelocation --> 8.029588342844211e-06\n",
      "HandlerFileRemoval --> 0.0025969477539067687\n",
      "MetaEdit --> 0.032927108273157396\n",
      "PlatformAddition --> 0.04071355272447089\n",
      "PlatformRemoval --> 0.02478796338439555\n",
      "TaskAddition --> 0.09700564719027054\n",
      "TaskEdit --> 0.131367103136446\n",
      "TaskRelocation --> 0.10165572465894764\n",
      "TaskRemoval --> 0.04486374508899089\n",
      "TaskFileAddition --> 0.023919346436197916\n",
      "TaskFileRelocation --> 0.0032191973788466195\n",
      "TaskFileRemoval --> 0.009312217801939863\n"
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(n_jobs=8)\n",
    "feature_importances = np.zeros(X_normal.shape[1])\n",
    "\n",
    "for i, (train, test) in enumerate(StratifiedKFold(n_splits=10).split(X_normal, y)):\n",
    "    clf2.fit(X_normal[train], y[train])\n",
    "    feature_importances += clf2.feature_importances_\n",
    "\n",
    "print(\"Weights of the features:\")\n",
    "feature_importances /= 10\n",
    "\n",
    "for feature_name, feature_weight in zip(filtered_data.columns[:-1], feature_importances):\n",
    "    print(feature_name, \"-->\", feature_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-dynamics",
   "metadata": {},
   "source": [
    "### Feature importances by feature permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genuine-cyprus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model ...\n",
      "Done!\n",
      "Calculating permutation importances ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"Fitting model ...\")\n",
    "clf3 = RandomForestClassifier(n_jobs=8)\n",
    "clf3.fit(X_normal, y)\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"Calculating permutation importances ...\")\n",
    "result = permutation_importance(clf3, X_normal, y, n_repeats=10, random_state=0)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "romantic-digit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockAddition --> 0.008678954291848784\n",
      "BlockEdit --> 0.000952568153983413\n",
      "BlockRelocation --> 0.0007076220572448166\n",
      "BlockRemoval --> 0.0044604381813508785\n",
      "RoleVariableAddition --> 0.020891482831093055\n",
      "RoleVariableEdit --> 0.011213087984033188\n",
      "RoleVariableRelocation --> 6.048051771323504e-05\n",
      "RoleVariableRemoval --> 0.0038616810559898517\n",
      "RoleVarFileAddition --> 0.0035910307392231335\n",
      "RoleVarFileRelocation --> 0.00027821038148089227\n",
      "RoleVarFileRemoval --> 0.000721230173730314\n",
      "DefaultVariableAddition --> 0.07402210562922422\n",
      "DefaultVariableEdit --> 0.025757140481122532\n",
      "DefaultVariableRelocation --> 0.0\n",
      "DefaultVariableRemoval --> 0.02261971362474865\n",
      "DefaultVarFileAddition --> 0.0014197801533181397\n",
      "DefaultVarFileRelocation --> 7.560064714151604e-05\n",
      "DefaultVarFileRemoval --> 0.00022831395436748725\n",
      "DependencyAddition --> 0.0023436200613877302\n",
      "DependencyRemoval --> 0.0014787486580885357\n",
      "HandlerBlockEdit --> 0.0\n",
      "HandlerBlockRelocation --> 0.0\n",
      "HandlerBlockRemoval --> 0.0004415077793065936\n",
      "HandlerTaskAddition --> 0.0017025265736275053\n",
      "HandlerTaskEdit --> 0.006436639097630703\n",
      "HandlerTaskRelocation --> 0.00036590713216507755\n",
      "HandlerTaskRemoval --> 0.0001587613589972392\n",
      "HandlerFileAddition --> 0.0007091340701876559\n",
      "HandlerFileRelocation --> 0.0\n",
      "HandlerFileRemoval --> 0.0002812344073665596\n",
      "MetaEdit --> 0.03377080907812573\n",
      "PlatformAddition --> 0.025309584650044636\n",
      "PlatformRemoval --> 0.009108365967612674\n",
      "TaskAddition --> 0.07515309131046163\n",
      "TaskEdit --> 0.06382811436865901\n",
      "TaskRelocation --> 0.038473169330329474\n",
      "TaskRemoval --> 0.02030179778338905\n",
      "TaskFileAddition --> 0.00745724783404147\n",
      "TaskFileRelocation --> 0.0003583470674509148\n",
      "TaskFileRemoval --> 0.0009752483481258789\n"
     ]
    }
   ],
   "source": [
    "for feature_name, feature_importance in zip(filtered_data.columns[:-1], result.importances_mean):\n",
    "    print(feature_name, \"-->\", feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-munich",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepting-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal number of features : 28\n",
      "\n",
      "Original Features on Data:  ['BlockAddition', 'BlockEdit', 'BlockRelocation', 'BlockRemoval', 'RoleVariableAddition', 'RoleVariableEdit', 'RoleVariableRelocation', 'RoleVariableRemoval', 'RoleVarFileAddition', 'RoleVarFileRelocation', 'RoleVarFileRemoval', 'DefaultVariableAddition', 'DefaultVariableEdit', 'DefaultVariableRelocation', 'DefaultVariableRemoval', 'DefaultVarFileAddition', 'DefaultVarFileRelocation', 'DefaultVarFileRemoval', 'DependencyAddition', 'DependencyRemoval', 'HandlerBlockEdit', 'HandlerBlockRelocation', 'HandlerBlockRemoval', 'HandlerTaskAddition', 'HandlerTaskEdit', 'HandlerTaskRelocation', 'HandlerTaskRemoval', 'HandlerFileAddition', 'HandlerFileRelocation', 'HandlerFileRemoval', 'MetaEdit', 'PlatformAddition', 'PlatformRemoval', 'TaskAddition', 'TaskEdit', 'TaskRelocation', 'TaskRemoval', 'TaskFileAddition', 'TaskFileRelocation', 'TaskFileRemoval']\n",
      "Ranking of Features:  [ 1  1  1  1  1  1  7  1  1  2  1  1  1 10  1  1  9  8  1  1 12 11  1  1\n",
      "  1  1  5  3 13  6  1  1  1  1  1  1  1  1  4  1]\n",
      "Selected Features:  ['BlockAddition', 'BlockEdit', 'BlockRelocation', 'BlockRemoval', 'RoleVariableAddition', 'RoleVariableEdit', 'RoleVariableRemoval', 'RoleVarFileAddition', 'RoleVarFileRemoval', 'DefaultVariableAddition', 'DefaultVariableEdit', 'DefaultVariableRemoval', 'DefaultVarFileAddition', 'DependencyAddition', 'DependencyRemoval', 'HandlerBlockRemoval', 'HandlerTaskAddition', 'HandlerTaskEdit', 'HandlerTaskRelocation', 'MetaEdit', 'PlatformAddition', 'PlatformRemoval', 'TaskAddition', 'TaskEdit', 'TaskRelocation', 'TaskRemoval', 'TaskFileAddition', 'TaskFileRemoval']\n",
      "Discarded Features:  ['HandlerBlockRelocation', 'HandlerFileRelocation', 'HandlerFileRemoval', 'DefaultVarFileRemoval', 'DefaultVarFileRelocation', 'HandlerFileAddition', 'TaskFileRelocation', 'RoleVarFileRelocation', 'DefaultVariableRelocation', 'HandlerTaskRemoval', 'RoleVariableRelocation', 'HandlerBlockEdit']\n"
     ]
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=clf, \n",
    "              cv=StratifiedKFold(n_splits=10), \n",
    "              scoring='f1_macro', \n",
    "              n_jobs=-1)\n",
    "\n",
    "X_new = rfecv.fit_transform(X_normal, y)\n",
    "\n",
    "print()\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "column_names = filtered_data.columns[:-1].tolist()\n",
    "selected_features = list()\n",
    "\n",
    "for i, value in enumerate(rfecv.support_):\n",
    "    if value:\n",
    "        selected_features.append(column_names[i])\n",
    "\n",
    "print()\n",
    "print(\"Original Features on Data: \", column_names)\n",
    "print(\"Ranking of Features: \", rfecv.ranking_)\n",
    "print(\"Selected Features: \", selected_features)\n",
    "\n",
    "discarded_features = list(set(column_names).difference(set(selected_features)))\n",
    "print(\"Discarded Features: \", discarded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "taken-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockAddition 1\n",
      "BlockEdit 1\n",
      "BlockRelocation 1\n",
      "BlockRemoval 1\n",
      "RoleVariableAddition 1\n",
      "RoleVariableEdit 1\n",
      "RoleVariableRelocation 8\n",
      "RoleVariableRemoval 1\n",
      "RoleVarFileAddition 1\n",
      "RoleVarFileRelocation 2\n",
      "RoleVarFileRemoval 1\n",
      "DefaultVariableAddition 1\n",
      "DefaultVariableEdit 1\n",
      "DefaultVariableRelocation 10\n",
      "DefaultVariableRemoval 1\n",
      "DefaultVarFileAddition 1\n",
      "DefaultVarFileRelocation 9\n",
      "DefaultVarFileRemoval 7\n",
      "DependencyAddition 1\n",
      "DependencyRemoval 1\n",
      "HandlerBlockEdit 12\n",
      "HandlerBlockRelocation 11\n",
      "HandlerBlockRemoval 1\n",
      "HandlerTaskAddition 1\n",
      "HandlerTaskEdit 1\n",
      "HandlerTaskRelocation 1\n",
      "HandlerTaskRemoval 5\n",
      "HandlerFileAddition 3\n",
      "HandlerFileRelocation 13\n",
      "HandlerFileRemoval 6\n",
      "MetaEdit 1\n",
      "PlatformAddition 1\n",
      "PlatformRemoval 1\n",
      "TaskAddition 1\n",
      "TaskEdit 1\n",
      "TaskRelocation 1\n",
      "TaskRemoval 1\n",
      "TaskFileAddition 1\n",
      "TaskFileRelocation 4\n",
      "TaskFileRemoval 1\n"
     ]
    }
   ],
   "source": [
    "for feature_name, ranking in zip(column_names, rfecv.ranking_):\n",
    "    print(feature_name, ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-stability",
   "metadata": {},
   "source": [
    "### Normalisation of the input with the features already selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "hispanic-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "transformer = RobustScaler()\n",
    "X_normal = transformer.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-physiology",
   "metadata": {},
   "source": [
    "### Stratified Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "motivated-transformation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of Precisions:  0.7289960910830076\n",
      "Mean of Recalls:  0.5653869618309398\n",
      "Confusion matrix:\n",
      "[[44897  2867   209]\n",
      " [ 8463  6335   207]\n",
      " [ 1517   574  1068]]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "X = X_normal\n",
    "\n",
    "precision_scores = list()\n",
    "recall_scores = list()\n",
    "confusion_matrices = list()\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    clf.fit(X[train], y[train])\n",
    "    y_predict = clf.predict(X[test])\n",
    "\n",
    "    precision_value = precision_score(y[test], y_predict, average=\"macro\")\n",
    "    recall_value = recall_score(y[test], y_predict, average=\"macro\")\n",
    "    conf_matrix = confusion_matrix(y[test], y_predict)\n",
    "\n",
    "    precision_scores.append(precision_value)\n",
    "    recall_scores.append(recall_value)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "\n",
    "print()\n",
    "print(\"Mean of Precisions: \", np.mean(precision_scores))\n",
    "print(\"Mean of Recalls: \", np.mean(recall_scores))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(sum(confusion_matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "determined-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean of Precisions:  0.7306407673441868\n",
      "Mean of Recalls:  0.5641582810197747\n",
      "Mean of F1-Scores:  0.610542723443403\n",
      "Confusion matrix:\n",
      "[[44789  2968   216]\n",
      " [ 8471  6361   173]\n",
      " [ 1519   582  1058]]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "X = X_normal\n",
    "\n",
    "precision_scores = list()\n",
    "recall_scores = list()\n",
    "f1_scores = list()\n",
    "confusion_matrices = list()\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    clf.fit(X[train], y[train])\n",
    "    y_predict = clf.predict(X[test])\n",
    "\n",
    "    precision_value = precision_score(y[test], y_predict, average=\"macro\")\n",
    "    recall_value = recall_score(y[test], y_predict, average=\"macro\")\n",
    "    f1_value = f1_score(y[test], y_predict, average=\"macro\")\n",
    "    conf_matrix = confusion_matrix(y[test], y_predict)\n",
    "\n",
    "    precision_scores.append(precision_value)\n",
    "    recall_scores.append(recall_value)\n",
    "    f1_scores.append(f1_value)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "\n",
    "print()\n",
    "print(\"Mean of Precisions: \", np.mean(precision_scores))\n",
    "print(\"Mean of Recalls: \", np.mean(recall_scores))\n",
    "print(\"Mean of F1-Scores: \", np.mean(f1_scores))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(sum(confusion_matrices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-compact",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "given-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "pickle.dump(clf, open(\"data/models/randomForest_old_no_balance.pickle\", \"wb\")) # Model for the old data\n",
    "\n",
    "# Data\n",
    "pickle.dump(X, open(\"data/transformed_data/X_train_old.pickle\", \"wb\"))\n",
    "pickle.dump(y, open(\"data/transformed_data/y_train_old.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
